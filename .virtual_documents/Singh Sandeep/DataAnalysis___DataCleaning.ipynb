#Data Cleaning
#This is the first step in our data analysis


# Import the required libraries and dependencies
import pandas as pd


# Define the path to the CSV file
data_path = "../Resources/Cleaned_HealthData.csv"


# Load the data without specifying dtype for problematic columns
df = pd.read_csv(
    data_path,
    dtype={
        'LocationAbbr': 'str',
        'LocationDesc': 'str',
        'GeographicLevel': 'str',
        'DataSource': 'str',
        'Class': 'str',
        'Topic': 'str',
        'Data_Value': 'float64',
        'Data_Value_Unit': 'str',
        'Data_Value_Type': 'str',
        'Data_Value_Footnote_Symbol': 'str',
        'Data_Value_Footnote': 'str',
        'Confidence_limit_Low': 'float64',
        'Confidence_limit_High': 'float64',
        'StratificationCategory1': 'str',
        'Stratification1': 'str',
        'StratificationCategory2': 'str',
        'Stratification2': 'str',
        'StratificationCategory3': 'str',
        'Stratification3': 'str',
        'LocationID': 'int64'  # Assuming it's an integer
    },
    low_memory=False
)


# Check for missing values
print(df.isnull().sum())


# Columns with known missing data that are critical for analysis
critical_columns_with_missing_data = [
    'Data_Value',
    'Confidence_limit_Low',
    'Confidence_limit_High'
]

# Filter out rows with missing critical data
df_filtered = df.dropna(subset=critical_columns_with_missing_data)

# Display the filtered DataFrame to verify
df_filtered


print(df_filtered.isnull().sum())


# Drop the columns with only missing values
columns_to_drop = ['Data_Value_Footnote_Symbol', 'Data_Value_Footnote']
df_cleaned = df_filtered.drop(columns=columns_to_drop)

# Drop the 'DataSource' column, not necessary for analysis
df_cleaned = df_cleaned.drop(columns=['DataSource'])

# Display the cleaned DataFrame to verify
df_cleaned


# Convert the 'Year' column to numeric, handling errors
# Anaconda Assistant provided this error handling
df_cleaned.loc[:, 'Year'] = pd.to_numeric(df_cleaned['Year'], errors='coerce')

# Drop any rows where 'Year' could not be converted to a valid integer
df_cleaned = df_cleaned.dropna(subset=['Year'])

# Convert 'Year' column to integer type
df_cleaned.loc[:, 'Year'] = df_cleaned['Year'].astype(int)

# Filter the dataset to include only rows from the most recent years (2010-2019)
df_recent_years = df_cleaned[df_cleaned['Year'] >= 2010]

# Check the number of rows in the filtered dataset
print(f"The filtered DataFrame (2010-2019) has {len(df_recent_years)} rows.")


# Check all columns in the DataFrame for unique values
for column in df_recent_years.columns:
    unique_values = df_recent_years[column].unique()
    if len(unique_values) == 1:
        print(f"The '{column}' column has the same value across all rows.")
        print(f"The single value is: {unique_values[0]}")


# List of columns that have the same value across all rows and should be dropped
columns_to_drop = [
    'GeographicLevel',
    'Class',
    'Data_Value_Unit',
    'Data_Value_Type',
    'StratificationCategory1',
    'StratificationCategory2',
    'StratificationCategory3'
]

# Drop the specified columns
df_recent_years = df_recent_years.drop(columns=columns_to_drop)

# Verify the columns have been dropped
print("Remaining columns after dropping non-unique columns:")
print(df_recent_years.columns)


# Check for duplicates
duplicate_rows = df_recent_years.duplicated().sum()
print(f"Number of duplicate rows: {duplicate_rows}")


# Example: Identifying potential outliers in 'Data_Value'
df_recent_years['Data_Value'].describe()


# Filtering out extreme outliers
lower_bound = df_recent_years['Data_Value'].quantile(0.01)
upper_bound = df_recent_years['Data_Value'].quantile(0.99)

df_recent_years = df_recent_years[(df_recent_years['Data_Value'] >= lower_bound) &
                                  (df_recent_years['Data_Value'] <= upper_bound)]
print(f"After outlier removal, the DataFrame has {len(df_recent_years)} rows.")


print(df_recent_years.dtypes)


# Rename the columns
df_recent_years = df_recent_years.rename(columns={
    'LocationAbbr': 'State',
    'LocationDesc': 'County',
    'Topic': 'CauseOfDeath',
    'Data_Value': 'MortalityRate',  # Assuming this represents the rate per 100,000
    'Confidence_limit_Low': 'ConfLow',
    'Confidence_limit_High': 'ConfHigh',
    'Stratification1': 'AgeGroup',
    'Stratification2': 'Race',
    'Stratification3': 'Sex'
})

# Verify the column renaming
print("Columns after renaming:")
print(df_recent_years.columns)



# Display the final cleaned DataFrame
df_recent_years


# Save the cleaned DataFrame to a new CSV file
df_recent_years.to_csv('Cleaned_HealthData.csv', index=False)


#Task 2


import matplotlib.pyplot as plt
import seaborn as sns

# import data
path = "../Resources/Cleaned_HealthData.csv"
heart = pd.read_csv(path)

# check first five rows:
heart.head(5)


# check bottom five rows:
heart.tail(5)


heart.nunique()


# Summary statistics
display(heart.groupby('CauseOfDeath')['MortalityRate'].describe())




#@title Your Title Here Trends Over Time
plt.figure(figsize=(14, 7))
sns.lineplot(data=heart, x='Year', y='MortalityRate', hue='CauseOfDeath')
plt.title('Trends in Mortality Rates Over Time')
plt.show()




#@title Boxplot by Cause of Death
plt.figure(figsize=(14, 7))
sns.boxplot(data=heart, x='CauseOfDeath', y='MortalityRate')
plt.title('Mortality Rate Distribution by Cause of Death')
plt.xticks(rotation=45)
plt.show()




#@title Age and Gender Analysis
plt.figure(figsize=(14, 7))
sns.boxplot(data=heart, x='AgeGroup', y='MortalityRate', hue='Sex')
plt.title('Mortality Rates by Age Group and Sex')
plt.show()




#@title Mortality Rates by Sex and Cause of Death
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
sns.boxplot(data=heart, x='Sex', y='MortalityRate', hue='CauseOfDeath')
plt.title('Mortality Rates by Sex and Cause of Death')
plt.show()



#@title Yearly Average Mortality Rates by Cause of Death
yearly_avg = heart.groupby(['Year', 'CauseOfDeath'])['MortalityRate'].mean().reset_index()
plt.figure(figsize=(14, 7))
sns.barplot(data=yearly_avg, x='Year', y='MortalityRate', hue='CauseOfDeath')
plt.title('Yearly Average Mortality Rates by Cause of Death')
plt.xlabel('Year')
plt.ylabel('Number of Deaths per 100,000')
plt.show()



#@title Race Based Average Mortality Rates by Cause of Death
yearly_avg = heart.groupby(['Race', 'CauseOfDeath'])['MortalityRate'].mean().reset_index()
plt.figure(figsize=(14, 7))
sns.barplot(data=yearly_avg, x='Race', y='MortalityRate', hue='CauseOfDeath')
plt.title('Race Average Mortality Rates by Cause of Death')
plt.xlabel('Race')
plt.ylabel('Number of Deaths per 100,000')
plt.show()



#@title Seperate Cateogrical Features & Numerical Features
import numpy as np
cat_cols=heart.select_dtypes(include=['object']).columns
num_cols = heart.select_dtypes(include=np.number).columns.tolist()
print("Categorical Variables:")
print(cat_cols)
print("Numerical Variables:")
print(num_cols)


#@title Display skewness of each numerical attribute
for col in num_cols:
    print(col)
    print('Skew :', round(heart[col].skew(), 2))
    plt.figure(figsize = (15, 4))
    plt.subplot(1, 2, 1)
    heart[col].hist(grid=False)
    plt.ylabel('count')
    plt.subplot(1, 2, 2)
    sns.boxplot(x=heart[col])
    plt.show()


import matplotlib.pyplot as plt
import seaborn as sns


# Plot 1: Average MortalityRate by State
plt.figure(figsize=(10,6))
heart.groupby('State')['MortalityRate'].mean().sort_values(ascending=False).plot.bar(fontsize=8).set_title("State Vs Average Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 2: Average MortalityRate by CauseOfDeath
plt.figure(figsize=(10,6))
heart.groupby('CauseOfDeath')['MortalityRate'].mean().sort_values(ascending=False).plot.bar(fontsize=12).set_title("CauseOfDeath Vs Average Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 3: Average MortalityRate by AgeGroup
plt.figure(figsize=(10,6))
heart.groupby('AgeGroup')['MortalityRate'].mean().sort_values(ascending=False).plot.bar(fontsize=12).set_title("Average AgeGroup Vs Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 4: Average MortalityRate by Race
plt.figure(figsize=(10,6))
heart.groupby('Race')['MortalityRate'].mean().sort_values(ascending=False).plot.bar(fontsize=12).set_title("Average Race Vs Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 5: Average MortalityRate by Sex
plt.figure(figsize=(10,6))
heart.groupby('Sex')['MortalityRate'].mean().sort_values(ascending=False).plot.bar(fontsize=12).set_title("Average Sex Vs Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 6: Average MortalityRate by Year (if Year is considered categorical for this analysis)
plt.figure(figsize=(10,6))
heart.groupby('Year')['MortalityRate'].mean().sort_values(ascending=False).plot.bar(fontsize=12).set_title("Average Year Vs Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 1: Average MortalityRate by State (Top 5 States)
plt.figure(figsize=(10,6))
top_states = heart.groupby('State')['MortalityRate'].mean().sort_values(ascending=False).head(5)
top_states.plot.bar(fontsize=12, color='skyblue').set_title("Top 5 States Vs Average Mortality Rate (2010-2019) ", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()



# Plot 2: Average MortalityRate by State (Bottom 5 States)
plt.figure(figsize=(10,6))
top_states = heart.groupby('State')['MortalityRate'].mean().sort_values(ascending=False).tail(5)
top_states.plot.bar(fontsize=12, color='red').set_title("Bottom 5 States Vs Average Mortality Rate (2010-2019) ", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 3: Average MortalityRate by County (Top 5 Counties)
plt.figure(figsize=(10,6))
top_county = heart.groupby('County')['MortalityRate'].mean().sort_values(ascending=False).head(5)
top_county.plot.bar(fontsize=12, color='skyblue').set_title("Top 5 Counties Vs Average Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 4: Average MortalityRate by County (Bottom 5 Counties)
plt.figure(figsize=(10,6))
top_states = heart.groupby('County')['MortalityRate'].mean().sort_values(ascending=False).tail(5)
top_states.plot.bar(fontsize=12, color='red').set_title("Bottom 5 Counties Vs Average Mortality Rate (2010-2019) ", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 5: Average MortalityRate by LocationID (Top 5 LocationID)
plt.figure(figsize=(10,6))
top_county = heart.groupby('LocationID')['MortalityRate'].mean().sort_values(ascending=False).head(5)
top_county.plot.bar(fontsize=12, color='skyblue').set_title("Top 5 LocationID Vs Average Mortality Rate  (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()


# Plot 6: Average MortalityRate by LocationID (Top 5 LocationID)
plt.figure(figsize=(10,6))
top_county = heart.groupby('LocationID')['MortalityRate'].mean().sort_values(ascending=False).tail(5)
top_county.plot.bar(fontsize=12, color='red').set_title("Bottom 5 Location ID Vs Average Mortality Rate (2010-2019)", fontsize=18)
plt.ylabel('Number of Deaths per 100,000')
plt.show()



